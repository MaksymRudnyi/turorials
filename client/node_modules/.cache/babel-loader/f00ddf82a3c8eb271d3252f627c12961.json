{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\n\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content');\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    });\n    return data(code);\n  }\n  /** @type {State} */\n\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return data;\n  }\n  /** @type {State} */\n\n\n  function contentEnd(code) {\n    effects.exit('chunkContent');\n    effects.exit('content');\n    return ok(code);\n  }\n  /** @type {State} */\n\n\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit('chunkContent');\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    });\n    previous = previous.next;\n    return data;\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent');\n    effects.enter('lineEnding');\n    effects.consume(code);\n    effects.exit('lineEnding');\n    return factorySpace(effects, prefixed, 'linePrefix');\n  }\n  /** @type {State} */\n\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    const tail = self.events[self.events.length - 1];\n\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === 'linePrefix' && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"names":["factorySpace","markdownLineEnding","subtokenize","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","ok","previous","start","code","enter","contentType","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","prefixed","tail","length","parser","constructs","disable","null","includes","type","sliceSerialize","interrupt","flow"],"sources":["C:/Users/apinto2/Desktop/teswordtomd/12 setembro/UPLOAD 9/turorials/client/node_modules/micromark-core-commonmark/lib/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n}\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n}\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    effects.enter('content')\n    previous = effects.enter('chunkContent', {\n      contentType: 'content'\n    })\n    return data(code)\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n  /** @type {State} */\n\n  function contentEnd(code) {\n    effects.exit('chunkContent')\n    effects.exit('content')\n    return ok(code)\n  }\n  /** @type {State} */\n\n  function contentContinue(code) {\n    effects.consume(code)\n    effects.exit('chunkContent')\n    previous.next = effects.enter('chunkContent', {\n      contentType: 'content',\n      previous\n    })\n    previous = previous.next\n    return data\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n  return startLookahead\n  /** @type {State} */\n\n  function startLookahead(code) {\n    effects.exit('chunkContent')\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, prefixed, 'linePrefix')\n  }\n  /** @type {State} */\n\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    const tail = self.events[self.events.length - 1]\n\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === 'linePrefix' &&\n      tail[2].sliceSerialize(tail[1], true).length >= 4\n    ) {\n      return ok(code)\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAQA,YAAR,QAA2B,yBAA3B;AACA,SAAQC,kBAAR,QAAiC,0BAAjC;AACA,SAAQC,WAAR,QAA0B,4BAA1B;AAEA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,OAAO,GAAG;EACrBC,QAAQ,EAAEC,eADW;EAErBC,OAAO,EAAEC;AAFY,CAAhB;AAIP;;AAEA,MAAMC,qBAAqB,GAAG;EAC5BJ,QAAQ,EAAEK,oBADkB;EAE5BC,OAAO,EAAE;AAFmB,CAA9B;AAIA;AACA;AACA;AACA;AACA;AACA;;AAEA,SAASH,cAAT,CAAwBI,MAAxB,EAAgC;EAC9BT,WAAW,CAACS,MAAD,CAAX;EACA,OAAOA,MAAP;AACD;AACD;;;AAEA,SAASN,eAAT,CAAyBO,OAAzB,EAAkCC,EAAlC,EAAsC;EACpC;EACA,IAAIC,QAAJ;EACA,OAAOC,KAAP;EACA;;EAEA,SAASA,KAAT,CAAeC,IAAf,EAAqB;IACnBJ,OAAO,CAACK,KAAR,CAAc,SAAd;IACAH,QAAQ,GAAGF,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;MACvCC,WAAW,EAAE;IAD0B,CAA9B,CAAX;IAGA,OAAOC,IAAI,CAACH,IAAD,CAAX;EACD;EACD;;;EAEA,SAASG,IAAT,CAAcH,IAAd,EAAoB;IAClB,IAAIA,IAAI,KAAK,IAAb,EAAmB;MACjB,OAAOI,UAAU,CAACJ,IAAD,CAAjB;IACD;;IAED,IAAIf,kBAAkB,CAACe,IAAD,CAAtB,EAA8B;MAC5B,OAAOJ,OAAO,CAACS,KAAR,CACLb,qBADK,EAELc,eAFK,EAGLF,UAHK,EAILJ,IAJK,CAAP;IAKD,CAXiB,CAWhB;;;IAEFJ,OAAO,CAACW,OAAR,CAAgBP,IAAhB;IACA,OAAOG,IAAP;EACD;EACD;;;EAEA,SAASC,UAAT,CAAoBJ,IAApB,EAA0B;IACxBJ,OAAO,CAACY,IAAR,CAAa,cAAb;IACAZ,OAAO,CAACY,IAAR,CAAa,SAAb;IACA,OAAOX,EAAE,CAACG,IAAD,CAAT;EACD;EACD;;;EAEA,SAASM,eAAT,CAAyBN,IAAzB,EAA+B;IAC7BJ,OAAO,CAACW,OAAR,CAAgBP,IAAhB;IACAJ,OAAO,CAACY,IAAR,CAAa,cAAb;IACAV,QAAQ,CAACW,IAAT,GAAgBb,OAAO,CAACK,KAAR,CAAc,cAAd,EAA8B;MAC5CC,WAAW,EAAE,SAD+B;MAE5CJ;IAF4C,CAA9B,CAAhB;IAIAA,QAAQ,GAAGA,QAAQ,CAACW,IAApB;IACA,OAAON,IAAP;EACD;AACF;AACD;;;AAEA,SAASV,oBAAT,CAA8BG,OAA9B,EAAuCC,EAAvC,EAA2Ca,GAA3C,EAAgD;EAC9C,MAAMC,IAAI,GAAG,IAAb;EACA,OAAOC,cAAP;EACA;;EAEA,SAASA,cAAT,CAAwBZ,IAAxB,EAA8B;IAC5BJ,OAAO,CAACY,IAAR,CAAa,cAAb;IACAZ,OAAO,CAACK,KAAR,CAAc,YAAd;IACAL,OAAO,CAACW,OAAR,CAAgBP,IAAhB;IACAJ,OAAO,CAACY,IAAR,CAAa,YAAb;IACA,OAAOxB,YAAY,CAACY,OAAD,EAAUiB,QAAV,EAAoB,YAApB,CAAnB;EACD;EACD;;;EAEA,SAASA,QAAT,CAAkBb,IAAlB,EAAwB;IACtB,IAAIA,IAAI,KAAK,IAAT,IAAiBf,kBAAkB,CAACe,IAAD,CAAvC,EAA+C;MAC7C,OAAOU,GAAG,CAACV,IAAD,CAAV;IACD;;IAED,MAAMc,IAAI,GAAGH,IAAI,CAAChB,MAAL,CAAYgB,IAAI,CAAChB,MAAL,CAAYoB,MAAZ,GAAqB,CAAjC,CAAb;;IAEA,IACE,CAACJ,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,QAApC,CAA6C,cAA7C,CAAD,IACAN,IADA,IAEAA,IAAI,CAAC,CAAD,CAAJ,CAAQO,IAAR,KAAiB,YAFjB,IAGAP,IAAI,CAAC,CAAD,CAAJ,CAAQQ,cAAR,CAAuBR,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCC,MAAtC,IAAgD,CAJlD,EAKE;MACA,OAAOlB,EAAE,CAACG,IAAD,CAAT;IACD;;IAED,OAAOJ,OAAO,CAAC2B,SAAR,CAAkBZ,IAAI,CAACK,MAAL,CAAYC,UAAZ,CAAuBO,IAAzC,EAA+Cd,GAA/C,EAAoDb,EAApD,EAAwDG,IAAxD,CAAP;EACD;AACF"},"metadata":{},"sourceType":"module"}